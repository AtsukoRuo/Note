分布式锁可以用在以下场景：

1. **防止缓存击穿**，在从数据库加载数据到缓存期间，如果不加锁，那么流量会打进数据库中。此时加锁保证了只会有一个请求同时打到数据库中

2. **保证接口幂等性**：提交接口添加分布式锁，第一次提交的时候会锁住，然后第二次提交发现有锁，就不会执行业务逻辑了。

3. **秒杀减库存等类似业务防止超卖的情况**

   

   ![img](./assets/1460000042536791.png)

注意：Redis 客户端 Redisson 以及 Zookeeper 的客户端 Curator 都为我们提供了各种锁。我们要善于使用它们，而不是重复造轮子。

# MySQL

在 MySQL 中实现分布式锁的关键技术就是索引的唯一性，它的工作流程如下：

1. 加锁时，向表 Insert 一条数据
2. 如果抛出 Key 重复异常，那么就说明有其他客户端持有该锁。此时我们只能重新执行 Insert 语句来重试加锁。
3. 持有锁的客户端在释放锁时，直接 Delete 表中的数据

下面设计一张分布式表：

~~~json
DROP TABLE IF EXISTS `common_lock`;
CREATE TABLE `common_lock` (
    `id` int NOT NULL,
    `entry_count` int NOT NULL,
    `thread_id` int NOT NULL,	
    `host_ip` varchar(30) NOT NULL,
     PRIMARY KEY (`id`),
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
~~~

- `id`：表示在 id 的资源上，有没有加锁
- `entry_count`：用于记录可重入次数的
- `thread_id` & `host_ip`：用于标识可重入的客户端。这里假定某台主机上竞争该锁的 多个 `thread_id` 都不相同

# Redis

## 互斥锁

Redisson 客户端提供了完善的分布式锁解决方案，我们先看一个 Demo

~~~java
Config config = new Config();
config.useClusterServers()
       // use "rediss://" for SSL connection
      .addNodeAddress("redis://127.0.0.1:7181")
      .addNodeAddress("redis://127.0.0.1:7182")
      .addNodeAddress("redis://127.0.0.1:7183");

RedissonClient redisson = Redisson.create(config);
RLock lock = redisson.getLock("myLock");

// 3.加锁
lock.lock();
try {
  ...
} finally {
    // 4.解锁
    lock.unlock();  
}
~~~

下面我们来底层剖析一下加锁的逻辑，它执行一段 Lua 脚本，通过该脚本来保证多个命令的原子性。该脚本的命令序列如下：

~~~lua
-- 如果不存在锁 KEYS[1]
if (redis.call('exists', KEYS[1]) == 0) then
    -- 使用 Hash 结构
    -- 这里的 ARGV[2] 是由 uuid:threadId 组成的一个唯一的数值
    -- 不能只使用 threadId，因为它在不同机器上是可以重复的
    -- 这里的 1，表示增加一次可重入次数
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    -- 设置过期时间为 ARGV[1]
    redis.call('pexpire', KEYS[1], ARGV[1]);
    -- 返回null代表成功
    return nil;
end;
-- 如果存在锁 KEYS[1] 并且 锁的[uuid:threadId]和请求中的相同，也就是说持有锁的线程是自己
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then 
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;

-- 锁的[uuid:threadId]和请求中的不相同
-- 返回剩余过期时间，用于重试获取锁。
return redis.call('pttl', KEYS[1]);
~~~

在集群中，先根据这个锁的 key 算出 hash 值，看看落在哪个 slot 槽上，也就找到了那台机器，然后只在那一台机器加锁。在 Redisson 中，锁的存储结构如下：

~~~redis
key: {
    [uuid:threadId]:锁次数
}
~~~

- key：用来标识一个锁
- [uuid:threadId]：用来标识持有锁的线程
- 锁次数：支持可重入



我们再来看释放锁的逻辑：

~~~lua
-- 如果线程并不持有锁，那么直接返回
if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then
    return nil;
end;

-- 给锁的可重入次数减一
local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1);
if (counter > 0) then
    -- 如果还有可重入次数，那么就续期
    redis.call('pexpire', KEYS[1], ARGV[2]);
    return 0;
else 
    -- 直接释放掉锁
    redis.call('del', KEYS[1]);
    redis.call('publish', KEYS[2], ARGV[1]);
    return 1;
end;
return nil;
~~~



等待获取锁的逻辑：如果获取锁失败了，那么给客户端返回一个超时时间，客户端等待这段时间后，再去重新获取该锁。



Redisson 内部有个 watchDog（看门狗）的机制来解决锁续期的问题。核心工作流程是定时监测业务，如果业务尚未执行结束，且锁的到期时间小于 2/3，那么就续期。值得一提的是，如果用户显式设置了过期时间，那么就不会开启看门狗机制。下面我们来看如何实现的：

~~~java
private void renewExpiration() {
    Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {
        @Override
        public void run(Timeout timeout) throws Exception {
            // 调用 lua 脚本进行续期
            RFuture<Boolean> future = renewExpirationAsync(threadId);
            future.onComplete((res, e) -> {
                // 报异常就移除 key
                if (e != null) {
                    // 省略 remove 的代码
                }
                // 续期成功的话就调用自己，进行下一轮续期。
                if (res) {
                    renewExpiration();
                } else {
                    // 续期失败的话就取消续期，移除 key 等操作
                    cancelExpirationRenewal(null);
                }
            });
        }
        // 这里是个知识点，续期线程在过期时间达到三分之一的时候工作，比如9s 过期时间，那么续期会在第 3 秒的时候工作
    }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS);
    ee.setTimeout(task);
}
~~~

下面是实现续期逻辑的 Lua 脚本：

~~~lua
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return 1;
end;
	return 0;
~~~

当锁释放时，立即取消 watchDog，防止重新续期。同时 Redisson 通过时间轮（`io.netty.util.HashedWheelTimer`）来维护 watchDog，避免了创建昂贵的线程。

## 分布式公平锁

Redisson 提供了公平锁机制，使用方式如下：

```java
RLock fairLock = redisson.getFairLock("anyLock");
fairLock.lock();
```

公平锁的核心就是三个数据结构：

- hash：存储锁以及重入次数
- list：线程的等待队列
- zset ：分数 score 用来存储等待线程的超时时间戳。

而对于非公平锁，无需 list 进行排队，就用一个 hash 结构来存储锁即可。

下面我们来看一下实现公平锁加锁的 Lua 脚本，它的参数如下：

- KEYS[1]：加锁的名字，`anyLock`；
- KEYS[2]：加锁等待队列，`redisson_lock_queue:{anyLock}`；
- KEYS[3]：等待队列中线程锁时间的 set 集合，`redisson_lock_timeout:{anyLock}`，是按照锁的时间戳存放到集合中的；
- ARGV[1]：锁超时时间，用在 Hash 中的；
- ARGV[2]：UUID:ThreadId 组合 `a3da2c83-b084-425c-a70f-5d9a08b37f31:1`；
- ARGV[3]：threadWaitTime 默认 300000。当要添加到队列时，之前队尾的超时时间戳 + threadWaitTime 就是当前线程在队列中的超时时间戳。
- ARGV[4]：currentTime 当前时间戳。

代码如下：

~~~lua
-- 在其他锁争夺资源时，会先从移除超时的线程
-- 这样做的目的是及时清理超时线程，避免堆积，以及确保下面的执行逻辑正确执行
while true do
    -- 从等待队列 redisson_lock_queue:{anyLock} 中获取第一个等待线程；
    local firstThreadId2 = redis.call("lindex", KEYS[2], 0)
    if firstThreadId2 == false then
        -- 等待队列为空，直接退出循环
        break;
    end
    
    -- 从等待线程超时集合 redisson_lock_timeout:{anyLock} 中获取第一个等待线程的分数；
    local timeout = tonumber(redis.call("zscore", KEYS[3], firstThreadId2));
    if timeout <= tonumber(ARGV[4]) then
        -- 超时了，则直接移除
        redis.call("zrem", KEYS[3], firstThreadId2);
        redis.call("lpop", KEYS[2]);
    else 
        -- 没有超时，直接退出循环
        break
    end
end


-- 锁 anyLock 不存在
-- 或者，等待队列 redisson_lock_queue:{anyLock} 为空，或者当前线程在队首
if (redis.call('exists', KEYS[1]) == 0)
    and ((redis.call('exists', KEYS[2]) == 0)
        or (redis.call('lindex', KEYS[2], 0) == ARGV[2])) then
    
    -- 从等待队列和超时集合中删除当前线程
    -- 这时候等待队列和超时集合都是空的，不执行操作；
    redis.call('lpop', KEYS[2]);
    redis.call('zrem', KEYS[3], ARGV[2]);
    
    -- 这里也不执行操作
    local keys = redis.call('zrange', KEYS[3], 0, -1);
    for i = 1, #keys, 1 do
        redis.call('zincrby', KEYS[3], -tonumber(ARGV[4]), keys[i]);
    end;

    -- 加锁并设置超时时间
    redis.call('hset', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;


-- 处理可重入的逻辑
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;

-- 走到这里的话，就说明获取锁失败了
local timeout = redis.call("zscore", KEYS[3], ARGV[2]);
if timeout ~= false then
    -- 返回前一个等待线程的剩余超时时间
    return timeout - tonumber(ARGV[3]) - tonumber(ARGV[4]);
end


--  走到这里的话，就说明这是新来的线程，要放在队列中等待
-- 从线程等待队列 redisson_lock_queue:{anyLock} 中获取最后一个线程；
local lastThreadId = redis.call('lindex', KEYS[2], -1);
local ttl;


if lastThreadId ~= false and lastThreadId ~= ARGV[2] then 
    -- 最后一个线程存在，且不是自己，那么获取它的超时时间
    ttl = tonumber(redis.call('zscore', KEYS[3], lastThreadId)) - tonumber(ARGV[4]);
else
    ttl = redis.call('pttl', KEYS[1]);
end;

-- 最后一个线程的超时时间 + 当前时间戳 + threadWaitTime 就是它的超时时间
local timeout = ttl + tonumber(ARGV[3]) + tonumber(ARGV[4]);

-- 使用 zadd 将 Thread3 放到等待线程有序集合，然后使用 rpush 将 Thread3 再放到等待队列中。
if redis.call('zadd', KEYS[3], timeout, ARGV[2]) == 1 then
    redis.call('rpush', KEYS[2], ARGV[2]);
end;
return ttl;
~~~



公平锁释放锁的 Lua 脚本：

- `KEYS[1]`：加锁的名字，`anyLock`；
- `KEYS[2]`：加锁等待队列，`redisson_lock_queue:{anyLock}`；
- `KEYS[3]`：等待队列中线程锁时间的 set 集合，`redisson_lock_timeout:{anyLock}`，是按照锁的时间戳存放到集合中的；
- `KEYS[4]`：`redisson_lock__channel:{anyLock}`；
- `ARGV[1]`：LockPubSub.UNLOCK_MESSAGE；
- `ARGV[2]`：锁在 Hash 中的超时时间
- `ARGV[3]`：UUID:ThreadId 组合 `58f6c4a2-9908-4957-b229-283a45359c4b:47`；
- `ARGV[4]`：currentTime 当前时间戳。

~~~lua
-- 和在加锁中的逻辑一样，这里就不再介绍
while true do
    local firstThreadId2 = redis.call("lindex", KEYS[2], 0)
    if firstThreadId2 == false then
        break;
    end
   
    local timeout = tonumber(redis.call("zacore", KEYS[3], firstThreadId2));
    if timeout <= tonumber(ARGV[4]) then
        redis.call("zrem", KEYS[3], firstThreadId2);
        redis.call("lpop", KEYS[2]);
    else 
        break
    end
end

-- 锁不存在
if (redis.call("exists", KEYS[1] == 0)) then
    local nextThreadId = redis.call("lindex", KEYS[2], 0);
    if nextThreadId ~= false then
        -- 通知队列中的第一个线程来获取锁
        redis.call("publish", KEYS[4].. ":"..nextThreadId, ARGV[1]);
    end
    return 1;
end

-- 锁存在，但不是自己持有的锁，直接退出
if (redis.call("hexists", KEYS[1], ARGV[3]) == 0) then
    return nil;
end

-- 处理可重入的逻辑
local counter = redis.call("hincrby", KEYS[1], ARGV[3], -1);
if (counter > 0) then 
    redis.call("pexpire", KEYS[1], ARGV[2]);
    return 0;
end

-- 删除，并通知队列中的第一个线程来获取锁
redis.call("del", KEY[1]);
local nextThreadId = redis.call("lindex", KEY[2], 0);
if nextThreadId ~= false then
    redis.call("publish", KEYS[4] .. ":" .. nextThreadId, ARGV[1]);
end
return 1;
~~~



## 分布式读写锁

读写锁在互斥锁的基础上，添加 mode 字段就可以了：

~~~json
"readWriteLock": {
    "mode": write,
    // 写锁下，只能有一个持有该锁的客户端
    "UUID:ThreadId:write": 1
}

"readWriteLock": {
    "mode": read,
    "uuid:threadId1": 2,
    "uuid:threadId2": 1
}
~~~

并不能直接在读锁上设置 hash 的过期时间，因为每个线程的共享锁的过期时间都不一致。因此，我们还要单独为每个线程维护一个超时时间，这对读锁的 watchDog 有所影响。而写锁就没有这个问题。

~~~shell
# 给 hash 结构续期
pexpire readWriteLock 30000

# 给单独读锁续期
pexpire {readWriteLock}:aaa:rwlock_timeout 30000
~~~



下面是一个使用 Demo：

~~~java
Config config = new Config();
config.useClusterServers()
	.addNodeAddress("redis://127.0.0.1:7001")
    .addNodeAddress("redis://127.0.0.1:7002")

RedissonClient redisson = Redisson.create(config);
RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");

rwlock.readLock().lock();
rwlock.writeLock().lock();
~~~



读锁的源码地址：`org.redisson.RedissonReadLock#tryLockInnerAsync`。参数列表：

1. KEYS[1]：锁名字 anyRWLock
2. KEYS[2]：当前线程在锁上的超时 key `{anyRWLock}:UUID:ThreadId:rwlock_timeout` 
3. ARGV[1]：锁在超时 Key 上的超时时间，默认 30s
4. ARGV[2]：当前线程，`UUID:ThreadId` 组成的字符串
5. ARGV[3]：写锁名字，`UUID:ThreadId:write` 

~~~lua
local mode = redis.call("hget", KEYS[1], "mode");

-- 如果锁不存在，那么就创建一个
if (mode == false) then
    redis.call('hset', KEYS[1], "mode", "read");
    redis.call("hset", KEYS[1], ARGV[2], 1);
    redis.call("set", KEYS[2], ..":1", 1);
    redis.call("pexpire", KEYS[2], .. ":1", ARGV[1]);
    redis.call("pexpire", KEYS[1], ARGV[1]);
    return nil;
end

-- 如果锁是读锁，或者，是写锁而且 Hash 中 UUID:ThreadId:write 存在
if (mode == "read") or (mode == "write" and redis.call("hexists", KEYS[1], ARGV[3]) == 1) then 
    -- 多个线程可以同时持有读锁，所以这里没必要做读锁的互斥判断
    -- 如果当前锁持有写锁，那么就执行降级操作
    local ind = redis.call("hincrby", KEYS[1], ARGV[2], 1);
    local key = KEYS[2] ..":".. ind;
    redis.call("set", key, 1);
    redis.call("pexpire", key, ARGV[1]);
    
    local remainTime = redis.call("pttl", KEYS[1]);
    redis.call("pexpire", KEYS[1], math.max(remainTime, ARGV[1]));
    return nil;
end

return reids.call("pttl", KEYS[1]);
~~~



写锁的源码地址：`org.redisson.RedissonWriteLock#tryLockInnerAsync`。参数列表：

1. KEYS[1]：当前锁 anyRWLock
2. ARGV[1]：锁在超时 Key 上的超时时间，默认 30s
3. ARGV[2]：写锁名字，`UUID:ThreadId:write` 组成的字符串

~~~lua
local mode = redis.call("hget", KEYS[1], "mode");
-- 如果没有锁，那么就创建一个
if (mode == false) then
    redis.call("hset", KEYS[1], "mode", "write");
    redis.call("hset", KEYS[1], ARGV[2], 1);
    redis.call("pexpire", KEYS[1], ARGV[1]);
    return nil;
end

-- 处理可重入的逻辑
if (mode == "write") then
    if (redis.call("hexisys", KEYS[1], ARGV[2]) == 1) then
        redis.call("hincrby", KEYS[1], ARGV[2], 1);
        local currentExpire = redis.call("pttl", KEYS[1]);
        redis.call("pexpire", KEYS[1], currentExpire + ARGV[1]));
        return nil;
    end
end

return reids.call("pttl", KEYS[1]);
~~~

读锁的 watchDog 不仅要续期 hashKey，还要单独为每个线程进行续期

## 联锁 MultiLock

联锁把多把锁合并成一个锁，然后它会保证所有锁都上锁成功后，才算成功。

~~~java
RLock lock1 = redissonInstance1.getLock("lock1");
RLock lock2 = redissonInstance2.getLock("lock2");
RLock lock3 = redissonInstance3.getLock("lock3");

RedissonMultiLock lock = new RedissonMultiLock(lock1, lock2, lock3);
// 同时加锁：lock1 lock2 lock3
// 所有的锁都上锁成功才算成功。
lock.lock();
...
lock.unlock();
~~~

RedissonMultiLock 的原理就是内部维护一个锁的集合，加锁/解锁的时候就通过遍历集合，调用每把锁自己的 lock/unlock 方法，至于底层是如何实现互斥、可重入等逻辑细节都是每把锁自己实现的。

在加锁过程中，如果有一个失败的加锁操作，那么 unlock 所有已经持有的锁。然后就会执行外部的 `while (true)` 逻辑，然后重新再走一遍 `RedissonMultiLock#tryLock`。

## 红锁

它是基于 Redis 的高可用分布式锁。直接说结论，**Redisson RedLock 已经被弃用**。了解其思想即可，下面就不给出实现了。推荐大家阅读两篇文章：

- Martin Kleppmann：How to do distributed locking[2] https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html
- Salvatore（Redis 作者）：Is Redlock safe?[3] http://antirez.com/news/101

它在 N 个 Master 个上依次加锁，如果至少有 $ N / 2 + 1$ 个成功加锁，那么就视为加锁成功。在保证高可用性的同时，也解决了主从模式下同步延迟的问题。

在实现上，它复用联锁的逻辑。它俩的唯一区别就是联锁允许失败0 个，而红锁就允许失败`锁总数 - (n/2)+1`个

## 限流工具

### Zookeeper

下面给出用 Zookeeper 的 Semaphore 伪实现：

~~~java
// 这里加上一个锁，保证创建节点以及获取数量是原子的，避免了线程安全问题。
lock.acquire();

try {
     // 创建临时节点
    PathAndBytesable<String> createBuilder = client
        .create()
        .creatingParentContainersIfNeeded()
        .withProtection()
        .withMode(CreateMode.EPHEMERAL_SEQUENTIAL);
    
    for(;;) {
        // 获取所有已经加锁的客户端数量，实际是已经创建了临时节点的数量。
        // 这里有一个监控器，用于监听节点删除事件，这样就可以从阻塞中唤醒出来。
        children = client.getChildren().usingWatcher(watcher).forPath(leasesPath);
        // 如果已经加锁的客户端数量小于等于允许数量。那直接 return 放行。
        if ( children.size() <= maxLeases) {
            break ;
        }
        // 阻塞，这里并不用释放锁，这使得其他客户端就只能排队等待，无法竞争。直到它成功获取锁后
         wait();
    }
} finally {
    lock.release();
}
~~~

释放锁：

~~~java
// 省略其他代码
private Lease makeLease(final String path) {
    return new Lease() {
        @Override
        public void close() throws IOException {
            try {
                // 直接删除临时顺序节点
                // 这个删除操作会唤醒正在阻塞的节点。
                client.delete().guaranteed().forPath(path);
            }
        }
    };
}
~~~

### Redis

使用示例：

~~~java
RSemaphore sempahore = redisson.getSeamphore("semaphore");
// 设置只有 3 个凭证
semaphore.trySetPermits(3);

// 获取一个凭证
semaphore.acquire();

// 释放一个凭证
semaphore.release();
~~~



设置凭证的 Lua 脚本，它有三个参数：

1. KEYS[1]：指定的 key 名 —— semaphore
2. KEYS[2]：redisson_sc:{semaphore}
3. ARGV[1]：凭证数 

~~~lua
local value = redis.call('get', KEYS[1]);
if (value == false or value == 0) then
    redis.call("set", KEY[1], ARGV[1]);
    redis.call("publish", KEYS[2], ARGV[1]);
    return 1;
end
return 0;
~~~

获取凭证的 Lua 脚本

1. KEYS[1]：指定的 key 名 —— semaphore
2. ARGV[1]：要获取的凭证数，默认 1

执行逻辑如下：

1. 获取 key semaphore 的值
2. 如果值大于等于 1（要获取的凭证数），对值进行递减
3. 成功返回 1，失败返回 0
4. 如果获取失败，则自旋等待

## CountDownLacth

使用示例：

~~~java
RCountDownLatch latch = redisson.getCountDownLatch("myCountDownLatch");

latch.trySetCount(3);

// 这里开始一个 countDown
latch.countDown();

// 这里要等待三个 countDown
latch.await();
~~~



设置门闩数量

~~~lua
if redis.call("exists", KEYS[1]) == 0 then
    redis.call("set", KEY[1], ARGV[2]);
	redis.call("publish", KEYS[2], ARGV[1]);
	return 1;
else 
    return 0;
end
~~~

减少门闩数量：

~~~lua
local v = redis.call("decr", KEYS[1]);
if v <= 0 then redis.call("del", KEYS[1]) end;
-- 向 await 发布通知
if v == 0 then redis.call('publish', KEYS[2], ARGV[1]) end;
~~~



# ZooKeeper

假设有 n 个客户端争相获取一个锁。为了获取锁，一个进程试着创建 /lock 节点，如果 该节点存在了，客户端就会监视这个 znode 节点的删除事件。当  /lock 被删除时，所有监视 /lock节点的客户端收到通知。但这会有羊群效应，就是说当删除时，会产生大量的事件流量。

让客户端创建一个有序的节点 `/lock/lock-XXX`。客户端通过 `getChildren` 方法来获取所有 `/lock`下的子节点，并判断自己创建的节点是否是最小的序列号。如果客户端创建的节点不是最小序列号，就根据序列号确定序列， 在前一个节点上设置监视点。这样，每个节点上设置的监视点只有最多一个客户端。避免了监控点的羊群效应。

设置一个监视点会使服务端在内存消耗上增加大约 250 到 300 个字节。如果存在一百万个监视点，估计会消耗 0.3GB 的内存。因此，开发者必须时刻注意所设置的监视点数量。

