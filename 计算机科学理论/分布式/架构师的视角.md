# 架构师的视角

[TOC]

## 远程服务

远程服务将计算机程序的工作范围从单机扩展到网络，是构建分布式系统的首要基础。

[远程服务调用](https://en.wikipedia.org/wiki/Remote_procedure_call)（Remote Procedure Call，RPC）的最初目的，就是**为了让计算机能够跟调用本地方法一样去调用远程方法**。

计算机科学家们的最初想法是，就是将 RPC 作为 “[进程间通信](https://en.wikipedia.org/wiki/Inter-process_communication)”（Inter-Process Communication，IPC）的一种特例来看待的，其中IPC包括：

- **管道**（Pipe）或者**具名管道**（Named Pipe）
- **信号**（Signal）
- **信号量**（Semaphore）
- **消息队列**（Message Queue）
- **共享内存**（Shared Memory）
- **套接字接口**（Socket）：当在本机进程间通信时，套接字接口是被优化过的，即不会经过网络协议栈，不需要打包拆包、计算校验和等操作，只是简单地将应用层数据从一个进程拷贝到另一个进程，这种进程间通信方式有个专名的名称：UNIX Domain Socket，又叫做 IPC Socket。

RPC的调用形式是透明的，这反而让程序员误以为**通信是无成本的**。对此， ACM 和 Sun 院士[Peter Deutsch](https://en.wikipedia.org/wiki/L._Peter_Deutsch)、套接字接口发明者[Bill Joy](https://en.wikipedia.org/wiki/Bill_Joy)、Java 之父[James Gosling](https://en.wikipedia.org/wiki/James_Gosling)等一众共同总结了[通过网络进行分布式运算的八宗罪](https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing)（8 Fallacies of Distributed Computing）：

1. The network is reliable —— 网络是可靠的。
2. Latency is zero —— 延迟是不存在的。
3. Bandwidth is infinite —— 带宽是无限的。
4. The network is secure —— 网络是安全的。
5. Topology doesn't change —— 拓扑结构是一成不变的。
6. There is one administrator —— 总会有一个管理员。
7. Transport cost is zero —— 不必考虑传输成本。
8. The network is homogeneous —— 网络是同质化的。

如果远程服务调用要弄透明化的话，就必须为这些罪过买单



各种RPC 协议都不外乎使用各种手段，来解决以下三个基本问题：

- **如何表示数据**，序列化协议
- **如何传递数据**，传输层协议。“[Wire Protocol](https://en.wikipedia.org/wiki/Wire_protocol)”来用于表示这种两个 Endpoint 之间交换有关异常、安全、认证、授权、事务等等数据的行为。
- **如何确定方法**：使用编号来代替方法名。DCE 实现了与语言无关的[接口描述语言](https://en.wikipedia.org/wiki/Interface_description_language)（Interface Description Language，IDL），此外还有唯一的绝不重复的编码方案[UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)（Universally Unique Identifier）



RPC框架很难同时做到简单、普适、高性能这三点，因此有众多的RPC框架： RMI（Sun/Oracle）、Thrift（Facebook/Apache）、Dubbo（阿里巴巴/Apache）、gRPC（Google）、Motan1/2（新浪）、Finagle（Twitter）、brpc（百度/Apache）、.NET Remoting（微软）、Arvo（Hadoop）、JSON-RPC 2.0（公开规范，JSON-RPC 工作组）……

每一个框架都有一个主要的发展方向

- 朝着**面向对象**发展，
- 朝着**性能**发展：代表为 gRPC 和 Thrift。决定 RPC 性能的主要就两个因素：序列化效率和信息密度。其中，信息密度取决于协议中有效荷载（Payload）所占总传输数据的比例大小。SOAP 使用 XML 作为信息载体就是一个很好的失败例子。gRPC 是基于 HTTP/2 的，支持多路复用和 Header 压缩，Thrift 则直接基于传输层的 TCP 协议来实现，省去了额外应用层协议的开销。
- 朝着**简化、通用**发展：代表为 JSON-RPC



## REST设计风格

REST （Representational State Transfer）在Roy Thomas Fielding 在 2000 年发表的博士论文《[Architectural Styles and the Design of Network-based Software Architectures](https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm)》中提出，其中的关键概念有：

- **资源**（Resource）：例如，一篇文章
- **表征**（Representation）：资源的表示形式。例如文章的PDF格式、HTML格式
- **状态**（State），有关资源的上下文信息。如果状态在客户端维护，那么就是无状态。例如，用户正在阅读的文章。
- **转移**（Transfer）：无论状态是由服务端还是客户端来提供的，状态转移这个行为逻辑必然只能由服务端来实现，因为只有服务端拥有该资源及其表征形式。例如，将“用户当前阅读的文章”转变成“下一篇文章”
- **统一接口**（Uniform Interface）：URI 是统一资源标识符，是一个名词。而 HTTP 中的请求方法，是一个动词，同时这也是一套统一接口，它包括GET、HEAD、POST、PUT、DELETE、TRACE、OPTIONS 七种基本操作。任何一个支持 HTTP 协议的服务器都会遵守这套规定，对特定的 URI 采取这些操作，服务器就会触发相应的表征状态转移。
- **超文本驱动**（Hypertext Driven）：页面的导航行为都不可能是预置于浏览器代码之中，而是由服务器所发出的请求响应信息（超文本）来驱动的。这与有专门的页面控制器的客户端软件，有着十分本质的区别。
- **自描述消息**（Self-Descriptive Messages）：由于资源的表征可能存在多种不同形态，在消息中应当有明确的信息，来告知客户端该消息的类型以及应如何处理这条消息。一种被广泛采用的自描述方法是在名为“Content-Type”的 HTTP Header 中，标识出[互联网媒体类型](https://en.wikipedia.org/wiki/Media_type)（MIME type）。譬如“Content-Type : application/json; charset=utf-8”，则说明该资源会以 JSON 的格式来返回，请使用 UTF-8 字符集进行处理。

> 术语上的细节
>
> - “REST”（**Re**presentational **S**tate **T**ransfer）实际上是“HTT”（**H**yper**t**ext **T**ransfer）的进一步抽象，两者就如同接口与实现类的关系一般。
>
> - 同时Fielding 提出 REST 时所谈论的范围是“架构风格与网络的软件架构设计”（Architectural Styles and Design of Network-based Software Architectures），而不是现在被人们所狭义理解的一种“远程服务设计风格”，前者包括后者。
>
> - REST 只能说是风格，而不是规范、协议。

### RESTful

Fielding 认为完全满足 REST 风格的系统应该满足以下六大原则：

- **服务端与客户端分离**（Client-Server）

- **无状态**（Stateless）：每一次从客户端发送的请求中，应包括所有的必要的上下文信息，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。但在大型系统中，请求中所携带的上下文数量完全有可能膨胀到不切实际的程度。

- **可缓存**（Cacheability）：无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性，即需要多次请求来完成功能。为了缓解这个问题，REST 允许客户端或者代理将服务端的应答缓存起来。

- **分层系统**（Layered System）：客户端无需知道是否直接到服务器，还是连接到代理。代理服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性

- **统一接口**（Uniform Interface）：系统设计的重点放在抽象系统该有哪些资源上，而不是抽象系统该有哪些行为（服务）上。

  像login、logout这样的服务，我们可以抽象出Session资源，那么login就对应 PUT Session，而logout对应 DELETE Session

- **按需代码**（[Code-On-Demand](https://en.wikipedia.org/wiki/Code_on_demand)）：这是一条可选原则。它是指按照客户端的请求，将可执行的软件程序从服务器发送到客户端的技术。[Java Applet](https://en.wikipedia.org/wiki/Java_applet)与[WebAssembly](https://en.wikipedia.org/wiki/WebAssembly)都是典型代表



### RMM成熟度

![image-20240110124803658](assets/image-20240110124803658.png)

0. The Swamp of [Plain Old XML](https://en.wikipedia.org/wiki/Plain_Old_XML)
1. Resources：开始引入资源的概念
2. HTTP Verbs：引入统一接口，映射到 HTTP 协议的方法上。
3. Hypermedia Controls：也就是之前介绍的「超文本驱动」。在 Fielding 论文里的说法是“Hypertext As The Engine Of Application State，HATEOAS”，其实都是指同一件事情。



### 不足与争议

问题一：**面向资源的编程思想只适合做 CRUD，面向过程、面向对象编程才能处理真正复杂的业务逻辑**

见解：HTTP 的四个最基础的命令 POST、GET、PUT 和 DELETE 很容易让人直接联想到 CRUD 操作。而且我们还可以去扩展方法，按 Google 推荐的 REST API 风格，[自定义方法](https://cloud.google.com/apis/design/custom_methods)应该放在资源路径末尾，嵌入冒号加自定义动词的后缀

~~~http
POST /user/user_id/cart/book_id:undelete

~~~



问题二：**REST 与 HTTP 完全绑定，不适合应用于要求高性能传输的场景中**

见解：这是有一定的道理的



问题三：**REST 不利于事务支持**

见解：这要看你要支持哪种事务了，如果只追求最终一致性，那么REST就足够了



问题四：**REST 没有传输可靠性支持**

见解：这是正确的，最简单的解决方式就是把消息再重发一遍，但这样做的前提是服务应具有[幂等性](https://zh.wikipedia.org/wiki/冪等)（Idempotency）



问题五：**REST 缺乏对资源进行“部分”和“批量”的处理能力**

见解：这也是正确的。HTTP协议完全没有对请求资源的结构化描述能力（但有非结构化的部分内容获取能力，即用于断点续传的[Range Header](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Range_requests)），我们必须专门设计一些抽象资源才能去应对这种问题。

### 与RPC的关系

REST的基本思想是面向资源来抽象问题；而RPC的是面向过程来抽象问题。REST 与 RPC 作为主流的两种远程调用方式，在使用上的确是有部分重合的。

面向资源的编程思想与另外两种主流编程思想，只是在抽象问题时所处的立场不同，并没有高下之分。

人们以面向方法的思想来设计 RPC API，随着时间推移，接口与方法越来越多却又各不相同，开发人员必须了解每一个方法才能正确使用它们，这样既耗时又容易出错。但REST可以缓解这种问题：

- 降低服务接口的学习成本。统一接口（Uniform Interface）将对资源的标准操作都映射到了标准的 HTTP 方法上去。

- 资源天然具有集合与层次结构。以方法为中心抽象的接口，由于方法是动词，逻辑上决定了每个接口都是互相独立的；但以资源为中心抽象的接口，由于资源是名词，天然就可以产生集合与层次结构。

  ~~~xml
  GET /posts - 获取所有文章
  GET /posts/{postId} - 获取特定文章
  POST /posts - 创建一篇文章
  PUT /posts/{postId} - 更新特定文章
  DELETE /posts/{postId} - 删除特定文章
  GET /posts/{postId}/comments - 获取特定文章的所有评论
  GET /posts/{postId}/comments/{commentId} - 获取特定文章的特定评论
  POST /posts/{postId}/comments - 创建一条评论
  PUT /posts/{postId}/comments/{commentId} - 更新特定评论
  DELETE /posts/{postId}/comments/{commentId} - 删除特定评论
  ~~~

  注意，虽然两个资源在URL上表现为嵌套关系，但是它们却对应不同的微服务。

- REST 绑定于 HTTP 协议



## 事务

事务是指一组读写操作的逻辑单元。事务往往会被赋予ACID属性，来保证数据的一致性（**C**onsistency）：

- **原子性**（**A**tomic）：，事务保证了在同一项业务处理过程中，对多个数据的修改，要么同时成功，要么同时被撤销。
- **隔离性**（**I**solation）：事务保证了在不同的业务处理过程中，各自业务正在读、写的数据互相独立，不会彼此影响。
- **持久性**（**D**urability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。

这里的**一致性**（**C**onsistency）是指在事务执行过程中，必须要维护数据的不变式。可见，A、I、D 是手段，C 是目的。



- 当一个服务只使用一个数据源时，通过 A、I、D 来获得一致性是最经典的做法。此时，多个并发事务所读写的数据能够被数据源感知是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间一致性被称为“内部一致性”。
- 当一个服务使用到多个不同的数据源，事情就变得困难了许多。此时，并发执行甚至是先后执行的多个事务，在时间线上的顺序并不由任何一个数据源来决定，这种涉及多个数据源的事务间一致性被称为“外部一致性”。

外部一致性问题通常很难再使用 A、I、D 来解决，但是外部一致性又是分布式系统中必然会遇到且必须要解决的问题。为此，我们要转变观念，即从“是或否”的二元属性转变为可以按不同强度分开讨论的多元属性。在确保代价可承受的前提下，获得强度尽可能高的一致性保障。

### 本地事务

本地事务是指单个服务使用单个数据源的的事务处理机制。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，是直接调用有关事务的接口（如 JDBC 接口）。

要想深入地讨论本地事务，就不得不了解一些数据库事务的实现原理，这可以追溯到[ARIES](https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics)理论（Algorithms for Recovery and Isolation Exploiting Semantics，ARIES），基于语义的恢复与隔离算法理论。

在 20 世纪 90 年代，[IBM Almaden 研究院](http://www.research.ibm.com/labs/almaden/)总结了研发原型数据库系统“IBM System R”的经验，发表了 ARIES 理论中最主要的三篇论文，其中《[ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging](https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf)》着重解决了 ACID 的其中两个属性：原子性（A）和持久性（D）在算法层面上应当如何实现。而另一篇《[ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes](http://vldb.org/conf/1990/P392.PDF)》则是现代数据库隔离性（I）奠基式的文章，下面，我们先从原子性和持久性说起。

#### 原子性和持久性

由于写入中间状态与崩溃都是无法避免的，为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施，这种数据恢复操作被称为「崩溃恢复」。

通过「Commit Logging」（提交日志）来实现事务的原子性和持久性是当今的主流方案，基本思路是

1. 将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式（在文件末尾顺序追加）记录到磁盘中
2. 写入完成后，会追加“提交记录”（Commit Record），表示事务成功提交。
3. 然后根据日志上的信息对真正的数据进行修改
4. 修改完成后，再往日志中加入一条“结束记录”（End Record），表示事务已完成持久化。

日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场即可，这保证了持久性；其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，这保证了原子性。

> 除了Commit Logging，还有另外一种称为“[Shadow Paging](https://en.wikipedia.org/wiki/Shadow_paging)”的事务实现机制。大体思路是当写入数据时，先复制一份副本，保留原数据，修改副本数据。当事务成功提交后，去修改引用数据的指针，现代磁盘的写操作可以保证这个修改指针的操作是原子性的。
>
> Shadow Paging 实现事务要比 Commit Logging 更加简单，但涉及隔离性与并发锁时，Shadow Paging 实现的事务并发能力就相对有限，因此在高性能的数据库中应用不多。

Commit Logging 存在一个先天缺陷，所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后，即使之前你的磁盘 I/O 足够空闲。如果某个事务修改的数据量非常庞大，那么会占用大量的内存缓冲区。

ARIES 提出了「Write-Ahead Logging」的日志改进方案，它将写入数据的时机，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况

- **FORCE**：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE
- **STEAL**：在事务提交前，允许变动数据提前写入则称为 STEAL

显然，Commit Logging 是 NO-FORCE，NO-STEAL的；而Write-Ahead Logging 是 NO-FORCE，STEAL的。

![image-20240121140300155](assets/image-20240121140300155.png)

它给出的解决办法是，增加了一种 Undo Log 日志类型（回滚日志）。当更新数据写入磁盘前，必须先记录 Undo Log，注明修改了哪个位置的数据、从什么值改成什么值，等等。以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除。之前在Commit Logging的日志被称为 Redo Log

Write-Ahead Logging 在崩溃恢复时会执行以下操作：

- **分析阶段**（Analysis）：该阶段从最后一次检查点（Checkpoint）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合。
- **重做阶段**（Redo）：从待恢复的事务集合中找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。
- **回滚阶段**（Undo）：此时集合中剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。

#### 隔离性

数据库通过锁机制来实现隔离性：

- **写锁**（Write Lock，也叫作排他锁，eXclusive Lock，简写为 X-Lock）：如果数据被加上2写锁，就只有持有写锁的事务才能对数据进行写入操作，而其他事务不能写入数据，也不能施加读锁或者写锁。写锁禁止其他事务施加读锁，而不是禁止事务读取数据。

- **读锁**（Read Lock，也叫作共享锁，Shared Lock，简写为 S-Lock）：多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。

  对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。但是不允许反向降级。

- **范围锁**（Range Lock）：加了范围锁后，不仅无法修改该范围内已有的数据，也不能在该范围内新增或删除任何数据，这是排他锁无法做到的

  
  
  

下面是不同级别的隔离性，依次从强到弱：

- **可串行化**：对事务所有读、写的数据全都加上读锁、写锁和范围锁，一直持续到事务结束。串行化访问提供了强度最高的隔离性。但是[并发控制理论](https://en.wikipedia.org/wiki/Concurrency_control)（Concurrency Control）阐述了隔离程度与并发能力是负相关的，即隔离程度越高，并发访问时的吞吐量就越低。

- **可重复读（Repeatable Read）**：对事务所涉及的数据加读锁和写锁，一直持续到事务结束。

  它存在[幻读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Phantom_reads)（Phantom Reads），例如：

  ~~~sql
  SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：1，事务： T1  暂不提交*/
  INSERT INTO books(name,price) VALUES ('深入理解Java虚拟机',90)	/* 时间顺序：2，事务： T2  提交*/
  SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：3，事务： T1 提交*/
  ~~~

  两次相同的查询就会得到不一样的结果，原因是可重复读没有范围锁，来禁止在该范围内插入新的数据。

- **读已提交（Read Committed）**：对事务涉及的数据加的写锁，一直持续到事务结束，但加在查询操作上的读锁，在查询完成后就马上会释放。

  它存在[不可重复读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Non-repeatable_reads)（Non-Repeatable Reads），例如：

  ~~~sql
  SELECT * FROM books WHERE id = 1;   						/* 时间顺序：1，事务： T1 */
  UPDATE books SET price = 110 WHERE id = 1; COMMIT;			/* 时间顺序：2，事务： T2 提交*/
  SELECT * FROM books WHERE id = 1; COMMIT;   				/* 时间顺序：3，事务： T1 提交*/
  ~~~

  这两次重复执行的查询结果就会不一样，原因是读已提交的隔离级别缺乏贯穿整个事务周期的读锁，无法禁止读取过的数据发生变化。

- **读未提交（Read Uncommitted）**：只对事务涉及的数据加上写锁，会一直持续到事务结束，但完全不加读锁。

  它存在[脏读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Dirty_reads)（Dirty Reads），例如：

  ```sql
  SELECT * FROM books WHERE id = 1;   						/* 时间顺序：1，事务： T1 */
  
  UPDATE books SET price = 90 WHERE id = 1;					/* 时间顺序：2，事务： T2 暂不提交*/
  
  SELECT * FROM books WHERE id = 1;		
  /* 时间顺序：3，事务： T1 */
  
  ROLLBACK;			  										/* 时间顺序：4，事务： T2 */
  ```

  写锁禁止其他事务施加读锁，而不是禁止事务读取数据，如果事务 T1 读取数据并不需要去加读锁的话，就会导致事务 T2 未提交的数据也马上就能被事务 T1 所读到。这同样是一个事务受到其他事务影响，隔离性被破坏的表现。

  假如隔离级别是读已提交的话，由于事务 T2 持有数据的写锁，所以事务 T1 的第二次查询就无法获得读锁，因此 T1 中的查询就会被阻塞，直至事务 T2 被提交或者回滚后才能得到结果。

读未提交不会有脏写问题（Dirty Write），即一个事务的没提交之前的修改可以被另外一个事务的修改覆盖掉，脏写已经不单纯是隔离性上的问题了，它将导致事务的原子性都无法实现，所以一般谈论隔离级别时不会将它纳入讨论范围内

除了都以锁来实现外，以上四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性。

针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“[多版本并发控制](https://en.wikipedia.org/wiki/Multiversion_concurrency_control)”（Multi-Version Concurrency Control，MVCC）的无锁优化方案被主流的商业数据库广泛采用。它的“无锁”是特指读取时不需要加锁。

MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。其中版本可以理解为每一行记录都存在两个不可见的字段：`CREATE_VERSION` 和 `DELETE_VERSION`，这两个字段记录的值都是事务 ID，事务 ID 是一个全局严格递增的数值，然后根据以下规则写入数据：

- 插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。
- 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。
- 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。

此时，如有另外一个事务要读取这些发生了变化的数据，将根据隔离级别来决定到底应该读取哪个版本的数据

- 隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。
- 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。

另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。

MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案。

此外，加锁的策略可以分为

- **“乐观加锁”（Optimistic Locking）**：认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。
- **“悲观加锁”（Pessimistic Locking）**：认为不先做加锁再访问数据，就肯定会出现问题。

如果竞争剧烈的话，乐观锁反而更慢。

### 全局事务

在本节里，全局事务是指单个服务使用多个数据源的事务处理机制。理论上的全局事务并没有「单个服务」的约束，它本来就是 DTP（[Distributed Transaction Processing](https://en.wikipedia.org/wiki/Distributed_transaction)）模型中的概念。但本节所讨论的内容是一种在分布式环境中仍追求强一致性的事务处理方案，为了避免与后续介绍的放弃了弱一致性事务处理方式（分布式事务）相互混淆，所以这里的全局事务所指范围有所缩减。

1991 年，为了解决分布式事务的一致性问题，[X/Open](https://en.wikipedia.org/wiki/X/Open)组织提出了一套名为[X/Open XA](https://en.wikipedia.org/wiki/X/Open_XA)（XA 是 eXtended Architecture 的缩写）的处理事务架构，其核心内容是定义了全局的事务管理器（Transaction Manager，用于协调事务，可以理解为主节点）和局部的资源管理器（Resource Manager，用于驱动本地事务，可以理解为从节点）之间的通信接口。XA 接口是双向的，能在多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作，实现全局事务的统一提交或者统一回滚。

XA 是一套语言无关的通用规范， Java 中专门定义了[JSR 907 Java Transaction API](https://www.jcp.org/en/jsr/detail?id=907)来实现XA规范。JTA 最主要的两个接口是：

- 事务管理器的接口：
  - `javax.transaction.TransactionManager`接口
  - `javax.transaction.UserTransaction`接口
- 满足 XA 规范的资源定义接口：`javax.transaction.xa.XAResource`。任何资源（JDBC、JMS 等等）如果想要支持 JTA，只要实现 XAResource 接口中的方法即可。



假如你平时以声明式事务来编码，不过就是标个`@Transactional`注解而已，但如果以编程式事务来实现的话，伪代码如下所示：

```java
public void buyBook(PaymentBill bill) {
    userTransaction.begin();
    warehouseTransaction.begin();
    businessTransaction.begin();
	try {
        userAccountService.pay(bill.getMoney());
        warehouseService.deliver(bill.getItems());
        businessAccountService.receipt(bill.getMoney());
        userTransaction.commit();
        warehouseTransaction.commit();
        businessTransaction.commit();
	} catch(Exception e) {
        userTransaction.rollback();
        warehouseTransaction.rollback();
        businessTransaction.rollback();
	}
}
```

从代码上可看出，程序的目的是要做三次事务提交，但实际上代码并不能这样写，试想一下，如果在`businessTransaction.commit()`中出现错误，代码转到`catch`块中执行，此时`userTransaction`和`warehouseTransaction`已经完成提交，再去调用`rollback()`方法已经无济于事，这将导致一部分数据被提交，另一部分被回滚，整个事务的一致性也就无法保证了。



为了解决这个问题（一个事务跨多节点），XA 将事务提交拆分成为两阶段过程：

- **准备阶段**（投票阶段）：在这一阶段，协调者询问事务的所有参与者是否准备好提交。参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。

- **提交阶段**（执行阶段）：
  - 如果所有参与者回复Prepared，那么协调者向参与者发起 Commit 指令，所有参与者立即执行提交操作
  - 任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，那么协调协调者向参与者发起 Abort 指令，所有参与者立即执回滚操作

![image-20240121154748941](assets/image-20240121154748941.png)

以上这两个过程被称为“[两段式提交](https://zh.wikipedia.org/wiki/二阶段提交)”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件：

- 在提交阶段网络是可靠的
- 节点的失联必须是短暂的

它有以下缺点：

- **单点问题**：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，那所有参与者都会受到影响
- **性能问题**：准备阶段的时间取决于响应最慢的从节点



后续又发展出了“[三段式提交](https://zh.wikipedia.org/wiki/三阶段提交)”（3 Phase Commit，3PC）协议来解决上面两个缺点：

- CanCommit阶段，减少因某个参与者崩溃而导致其他参与者需要做回滚操作的可能性。
- PreCommit阶段
- DoCommit 阶段

![image-20240121161959489](assets/image-20240121161959489.png)

### 分布式事务

分布式事务（Distributed Transaction）特指业务上关联的多个服务同时访问多个数据源的事务处理机制。

1985 年 Fischer、Lynch、Paterson 提出了“[FLP 不可能原理](https://en.wikipedia.org/wiki/Consensus_(computer_science)#Solvability_results_for_some_agreement_problems)”，证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成强一致性结果。

CAP 定理（Consistency、Availability、Partition Tolerance Theorem），也称为 Brewer 定理。这个定理描述了：在涉及分布式系统中的共享数据的问题时，以下三个特性最多只能同时满足其中两个：

- **一致性**（**C**onsistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。

- **可用性**（**A**vailability）：代表系统不间断地提供服务的能力，这里有两个与其密切的概念：

  - 可靠性，使用平均无故障时间（Mean Time Between Failure，MTBF）来度量
  - 可维护性，使用平均可修复时间（Mean Time To Repair，MTTR）来度量。

  可用性的表征如下：
  $$
  A=MTBF/（MTBF+MTTR）
  $$
  譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。

- **分区容忍性**（**P**artition Tolerance）：部分节点因网络原因而失联后，系统仍能正确地提供服务的能力。这里网络分区正是指在网络中一部分节点无法和其他节点进行信息通信。

  

下面分析分别舍弃 C、A、P 时所带来的不同影响：

- **放弃分区容忍性**（CA without P）：意味着我们将假设节点之间通信永远是可靠的。
- **放弃可用性**（CP without A）：意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中。
- **放弃一致性**（AP without C）：意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。

选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择。 因为P 是分布式网络的天然属性，这是无法放弃的；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值。

但是我们可以追求「弱一致性」中的「最终一致性」。最终一致性的概念是 eBay 的系统架构师 Dan Pritchett 在 2008 年在 ACM 发表的论文《[Base: An Acid Alternative](https://queue.acm.org/detail.cfm?id=1394128)》中提出的。最终一致性的概念是 eBay 的系统架构师 Dan Pritchett 在 2008 年在 ACM 发表的论文《[Base: An Acid Alternative](https://queue.acm.org/detail.cfm?id=1394128)》中提出的。其中，BASE 是基本可用性（**B**asically **A**vailable）、柔性事务（**S**oft State）和最终一致性（**E**ventually Consistent）的缩写

此时「事务」一词的含义其实也同样被拓展了，人们把具有 ACID属性 （强一致性）的事务称为“刚性事务”，而把保证最终一致性的事务统称为「柔性事务」。



#### 可靠事件队列

![image-20240121173758339](assets/image-20240121173758339.png)

以上这种靠着持续重试来保证可靠性的解决方案，称为“[最大努力交付](https://en.wikipedia.org/wiki/Best-effort_delivery)。

这种方案虽然简单，但是没有

#### TCC 事务

TCC是“Try-Confirm-Cancel”三个单词的缩写，是由数据库专家 Pat Helland 在 2007 年撰写的论文《[Life beyond Distributed Transactions: An Apostate’s Opinion](https://database.cs.wisc.edu/cidr/cidr2007/papers/cidr07p15.pdf)》中提出。它是一种业务侵入式较强的事务方案，要求业务处理过程必须拆分为“预留业务资源”和“确认/释放消费资源”两个子过程。

虽然可靠事务队列的实现简单，但是整个过程完全没有任何隔离性可言。

- **Try**：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好全部需用到的业务资源（保障隔离性）
- **Confirm**：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。
- **Cancel**：取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。



