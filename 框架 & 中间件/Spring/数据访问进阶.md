# 数据访问进阶

[TOC]



## 连接池的配置

亟需解决的问题：

- 连接数据库用的密码属于需要保护的敏感信息，不能直接放在配置文件里
- 为了方便排查问题，希望能记录所有执行的SQL

### HikariCP 与 Jasypt 实现密码加密

HikariCP数据连接池本身并不提供加密功能，必须配合 **Jasypt （Java Simplified Encryption）**加密工具来实现这项功能。

1. 在 pom.xml 中添加 `jasypt-spring-boot-starter` 依赖：

   ~~~xml
   <dependency>
       <groupId>com.github.ulisesbocchio</groupId>
       <artifactId>jasypt-spring-boot-starter</artifactId>
       <version>3.0.3</version>
   </dependency>
   ~~~

3. 要进行加密，可以直接用 Jasypt 的 Jar 包（在m2仓库中），调用其中的CLI 的类。

   ~~~xml
   java -cp ./jasypt-1.9.3.jar org.jasypt.intf.cli.JasyptPBEStringEncryptionCLI 
   
   input=明文 password=密钥
   
   algorithm=PBEWITHHMACSHA512ANDAES_256 
   
   ivGeneratorClassName=org.jasypt.iv.RandomIvGenerator
   
   saltGeneratorClassName=org.jasypt.salt.RandomSaltGenerator
   ~~~

   假设明文和密钥都设置为`binary-tea`，那么输出应该是：

   ~~~xml‘
   X401LMpOiBz7+4gOXybK9cQdDOYlqX7mWXmmj6aGZPGWwjqcbf/80hj0vQWqhaqa
   ~~~

   在 `application.properties` 中，将 `spring.datasource.password` 修改为 `ENC(X401LMpOiBz7+4gOXybK9cQdDOYlqX7mWXmmj6aGZPGWwjqcbf/80hj0vQWqhaqa)` 就完成了配置的修改。

   

4. 在运行时提供解密的密钥。密钥一般

   1. 放在配置文件中（`jasypt.encryptor.password`）

      ~~~bash
      java -jar demo.jar --Djasypt.encryptor.password="ADUMDFUOV7834*"
      ~~~

   2. 或者环境变量（ `JASYPT_ENCRYPTOR_PASSWORD`）

      ~~~java
      export ENCRYPTOR_PASSWORD=ADUMDFUOV7834*
      
      java -jar -Djasypt.encryptor.password=$ENCRYPTOR_PASSWORD
      ~~~

      

   Jasypt相关的配置配置。

| 配置项                                      | 默认值                                | 说明             |
| :------------------------------------------ | :------------------------------------ | :--------------- |
| `jasypt.encryptor.algorithm`                | `PBEWITHHMACSHA512ANDAES_256`         | 加解密算法       |
| `jasypt.encryptor.provider-name`            | `SunJCE`                              | 加密提供者       |
| `jasypt.encryptor.salt-generator-classname` | `org.jasypt.salt.RandomSaltGenerator` | 盐生成器         |
| `jasypt.encryptor.iv-generator-classname`   | `org.jasypt.iv.RandomIvGenerator`     | 初始化向量生成器 |
| `jasypt.encryptor.password`                 | 一般不使用，要不加密的意义在哪里？    | 密钥             |

Jasypt可以加密任何的配置项！加密步骤和上述一致。

###  HikariCP 与 P6SPY 实现 SQL 记录

HikariCP 本身并没有提供 SQL 日志的功能，因此需要借助 P6SPY来记录 SQL。首先，在 pom.xml 中引入 P6SPY 的依赖：

~~~xml
<dependency>
    <groupId>p6spy</groupId>
    <artifactId>p6spy</artifactId>
    <version>3.9.1</version>
</dependency>
~~~

接下来，调整连接池的配置：

~~~xml
spring.datasource.driver-class-name=com.p6spy.engine.spy.P6SpyDriver
spring.datasource.url=jdbc:p6spy:mysql://localhost:3306/test?useUnicode=true&characterEncoding=UTF-8。
~~~

最后，我们还需要一个 P6SPY 的配置文件 `spy.properties`。P6SPY 配置文件中的基本配置项如下：

| 配置项                     | 默认值                                                       | 说明 **5**                                                   |
| :------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| `dateformat`               | 默认使用时间戳的形式                                         | 日期格式，使用 `SimpleDateFormat` 的格式进行配置             |
| `logMessageFormat`         | `com.p6spy.engine.spy.appender.SingleLineFormat`             | 日志格式化类，可以在 `SingleLineFormat` 和 `CustomLineFormat` 之间选择 |
| `customLogMessageFormat`   | `%(currentTime)|%(executionTime)|%(category)|connection%(connectionId)|%(sqlSingleLine)` | `CustomLineFormat` 使用的输出格式                            |
| `appender`                 | `com.p6spy.engine.spy.appender.FileLogger`                   | 打印日志使用的 `Appender`，可以在 `FileLogger`、`SthoutLogger` 和 `Slf4JLogger` 之间选择 |
| `logfile`                  | spy.log                                                      | `FileLogger` 输出的日志文件                                  |
| `outagedetection`          | `false`                                                      | 是否开启慢 SQL 检测，当这个开关开启时，除了慢的 SQL 语句其他语句都不会再输出了 |
| `outagedetectioninterval`  | `60`                                                         | 慢 SQL 执行检测的间隔时间，单位是秒                          |
| `realdatasourceclass`      |                                                              | 真实的数据源类名，一般都能自动检测出实际需要的驱动类名       |
| `realdatasourceproperties` |                                                              | 真实的数据源配置属性，配置项用键值对形式表示，键与值用分号分隔，不同的键值对之间用逗号分隔 |

 `spy.properties`的内容示例：

~~~xml
appender=com.p6spy.engine.spy.appender.Slf4JLogger
dateformat=yyyyMMdd'T'HH:mm:ss
~~~



### 使用 Druid 内置功能实现密码加密

Druid 内置了数据库密码的加密功能，使用 RSA 非对称算法来进行加解密。使用 Druid 提供的命令行工具来生成密钥和密文（在m2仓库中）：

~~~java
java -cp druid-1.2.8.jar com.alibaba.druid.filter.config.ConfigTools 密码明文
~~~

假设密码明文是 `binary-tea`，则输出会类似下面这样：

~~~xml
privateKey:MIIBUwIBADANBgkqhkiG9w0BAQEFAASCAT0wggE5AgEAAkEAggg3wZKK1/bzA4M4JQ8CtoX48+5poBLFUvMJwxBtnss1o
UEKacWbw2C0vym+WMMSMgm6R+kCrliJqZ6r8MbYuwIDAQABAkAwntQCTEIgOJVrVdBTgwZXq0aIJzhVg09HEdsvld/3RKnQa5WYBbHnw
8zEpptF7VCckVEzQDsOY2zzTmCJO0bRAiEAwUqm7RxrVlyKJ2DEoPIzpXbL+g/aW+FO4KA4pVkDq8MCIQCsN7TeYokq8gugiLNngUbz
BuCL59ovLZUcmkBIbtVnqQIgYTjvZWxaAQJi6xOdU2b/20Y5qvm2V2ioiAuO8nwngIkCIAquleBpWjq4srHtaLtV0HHIjmr/IZBlkm
coxi33+fKpAiAyiVc+QJCtRAZrf8Q5KKi8K2wP5TzxopIWAi7l15MSow==


publicKey:MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIIIN8GSitf28wODOCUPAraF+PPuaaASxVLzCcMQbZ7LNaFBCmnFm8NgtL8pvl
jDEjIJukfpAq5Yiameq/DG2LsCAwEAAQ==


password:gTCrgZfRos9fKw3OOyhkWKaKeiwDrUCTkwIskdB+MdxMQF9CGwVY4wIiIm131Aivt4nEXEHLwavWKMOJTRqjIQ==
~~~

接下来，要在 `application.properties` 中开启密码加密功能：

~~~xml
spring.datasource.password=gTCrgZfRos9fKw3OOyhkWKaKeiwDrUCTkwIskdB+MdxMQF9CGwVY4wIiIm131Aivt4nEXEHLwavWKMOJTRqjIQ==

<!--让 Druid 加载 ConfigFilter 这个过滤器-->
spring.datasource.druid.filters=config

spring.datasource.druid.connection-properties=config.decrypt=true;config.decrypt.key=${publicKey}

<!--提供公钥-->
publicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAIIIN8GSitf28wODOCUPAraF+PPuaaASxVLzCcMQbZ7LNaFBCmnFm8NgtL8pvljDEjIJukfpAq5Yiameq/DG2LsCAwEAAQ==
~~~

此时，可以在命令行上设置系统属性 `-Ddruid.config.decrypt.key=` 来提供密钥。



还可以`druid.connection`配置还可以改为

~~~XML
spring.datasource.druid.connection-properties=config.decrypt=true;config.file=外部 Druid 配置文件路径
~~~

这样需要一个本地文件来存储`config.decrypt.key=` 密钥和 `password=` 密码密文



Druid 配置加密的逻辑基本都在 `ConfigFilter` 里，它的大致逻辑是这样的：

1. 在 Druid 加载 `Filter` 时，会调用其中的 `init()` 初始化方法；

2. `init()` 会从 `DruidDataSource` 的 `connectProperties` 属性，以及指定的配置文件中获取配置；

3. 判断是否需要解密密码；

4. 如果需要解密，再从第 (2) 步的两个位置获取解密的密钥；

5. 解密获得密码明文并进行判断。



### 使用 Druid 内置功能实现 SQL 记录

Druid内置了日志功能，与加密功能一样，这些功能也是通过 `Filter` 来实现的。在 `application.properties` 中，可以配置多个过滤器：

~~~xml
spring.datasource.druid.filters=config,slf4j,stat
~~~

Druid 一共提供了针对四个不同日志框架的 `LogFilter` 类，在配置时可以使用它们的别名。

- 对应 Log4j 1.*x* 的 `Log4jFilter`，别名 `log4j`。
- 对应 Log4j 2.*x* 的 `Log4j2Filter`，别名 `log4j2`。
- 对应 Commongs Logging 的 `CommonsLogFilter`，别名 `commonlogging`。
- 对应 SLF4J 的 `Slf4jLogFilter`，别名 `slf4j`。
- 此外，Druid 还提供了一个慢 SQL 统计的过滤器 `StatFilter`，别名是 `stat`。它有三个参数：
  - `druid.stat.logSlowSql`，是否打印慢 SQL，默认值为 `false`；
  - `druid.stat.slowSqlMillis`，用来定义多慢的 SQL 属于慢 SQL，默认值为 `3000`，单位毫秒；
  - `druid.stat.mergeSql`，在统计时是否合并 SQL，默认值为 `false`。



通过log4j.properties文件配置日志输出选项（如果没有提供，则默认是debug级别的）

~~~xml
  log4j.logger.druid.sql=warn,stdout
  log4j.logger.druid.sql.DataSource=warn,stdout
  log4j.logger.druid.sql.Connection=warn,stdout
  log4j.logger.druid.sql.Statement=warn,stdout
  log4j.logger.druid.sql.ResultSet=warn,stdout
~~~

在`application.properties`中配置：

~~~xml
spring.datasource.druid.connection-properties=
	druid.log.stmt.executableSql=true;
	druid.stat.logSlowSql=true
~~~



**`LogFilter` 中用到的 `Logger` 名称和配置**

| `Logger` 名称          | 配置项                               | 说明                                              |
| :--------------------- | :----------------------------------- | :------------------------------------------------ |
| `druid.sql.DataSource` |                                      | 打印关于 `DataSource` 的日志                      |
| `druid.sql.Connection` | `druid.log.conn=true`                | 打印关于 `Connection` 的日志                      |
| `druid.sql.Statement`  | `druid.log.stmt=true`                | 打印关于 `Statement` 的日志                       |
| `druid.sql.Statement`  | `druid.log.stmt.executableSql=false` | 在开启了 `Statement` 的日志时，是否打印执行的 SQL |
| `druid.sql.ResultSet`  | `druid.log.rs=true`                  | 打印关于 `ResultSet` 的日志                       |



### Druid 的 Filter 扩展

Druid 的 `Filter` 是个非常有用的机制，可以拦截 `DruidDataSource`、`Connection`、`Statement`、`PreparedStatement`、`CallableStatement`、`ResultSet`、`ResultSetMetaData`、`Wrapper` 和 `Clob` 上方法的执行。这其中使用了责任链模式，也就是将不同的过滤器串联在一起，以实现不同的功能。



我们可以基于Filter做出自己的扩展。而直接实现Filter接口太过于麻烦，有太多的方法需要我们覆写。此时，继承 `FilterAdapter` 或者 `FilterEventAdapter` 会是更好的选择。`FilterAdapter` 为每个方法都提供了默认实现，例如，`preparedStatement_executeUpdate()` 方法的默认实现如下：

~~~java
public int preparedStatement_executeUpdate(FilterChain chain, PreparedStatementProxy statement)
throws SQLException {
    return chain.preparedStatement_executeUpdate(statement);
}
~~~

`FilterEventAdapter` 是 `FilterAdapter` 的子类，它在执行责任链的基础之上，又增加了执行前后的动作，以 `statement_execute()` 为例，它的实现是下面这样的：

~~~java
public boolean statement_execute(FilterChain chain, StatementProxy statement, String sql,
String columnNames[]) throws SQLException {
    statementExecuteBefore(statement, sql);
    try {
        boolean firstResult = super.statement_execute(chain, statement, sql, columnNames);
        this.statementExecuteAfter(statement, sql, firstResult);
        return firstResult;
    } catch (SQLException error) {
        statement_executeErrorAfter(statement, sql, error);
        throw error;
    } catch (RuntimeException error) {
        statement_executeErrorAfter(statement, sql, error);
        throw error;
    } catch (Error error) {
        statement_executeErrorAfter(statement, sql, error);
        throw error;
    }
}
~~~

我们可以根据自己的需要，选择性覆盖一些方法。下面，我们通过「在建立`Connection` 前后，打印一些日志」这个例子来介绍如何自定义`Filter`：

~~~java
@Slf4j
@AutoLoad // 这个注解稍后解释
public class ConnectionConnectFilter extends FilterEventAdapter {
    @Override
    public void connection_connectBefore(FilterChain chain, Properties info) {
        log.info("Trying to create a new Connection.");
        super.connection_connectBefore(chain, info);
    }

    @Override
    public void connection_connectAfter(ConnectionProxy connection) {
        super.connection_connectAfter(connection);
        log.info("We have a new connected Connection.");
    }
}
~~~

在加载 `Filter` 有三种方式：

1. 在配置文件中通过别名来选择要加载的 `Filter`。别名与具体类的对应关系配置在 META-INF/druid-filter.properties 里，内置的文件内容如下所示：

   ~~~xml
   druid.filters.default=com.alibaba.druid.filter.stat.StatFilter
   druid.filters.stat=com.alibaba.druid.filter.stat.StatFilter
   druid.filters.mergeStat=com.alibaba.druid.filter.stat.MergeStatFilter
   druid.filters.counter=com.alibaba.druid.filter.stat.StatFilter
   druid.filters.encoding=com.alibaba.druid.filter.encoding.EncodingConvertFilter
   druid.filters.log4j=com.alibaba.druid.filter.logging.Log4jFilter
   druid.filters.log4j2=com.alibaba.druid.filter.logging.Log4j2Filter
   druid.filters.slf4j=com.alibaba.druid.filter.logging.Slf4jLogFilter
   druid.filters.commonlogging=com.alibaba.druid.filter.logging.CommonsLogFilter
   druid.filters.commonLogging=com.alibaba.druid.filter.logging.CommonsLogFilter
   druid.filters.wall=com.alibaba.druid.wall.WallFilter
   druid.filters.config=com.alibaba.druid.filter.config.ConfigFilter
   ~~~

   我们可以在自己的工程里也创建一个 META-INF/druid-filter.properties 文件，内容是之前 `ConnectionConnectFilter` 的映射：

   ~~~xml
   druid.filters.connectLog=learning.spring.binarytea.support.ConnectionConnectFilter

2.  类上加了 `@AutoLoad` 注解，让 Druid 自动加载 `Filter`。

3. 在 Spring 上下文中配置 `Filter` 对应的 Bean



## Spring的缓存抽象

![{%}](assets/022.jpg)

当然，这里还要考虑缓存内容过期、超过缓存上限时内容淘汰、数据写入缓存时是否加锁等问题。

Spring Framework将上述流程做了一层抽象，它通过注解或者 XML 的方式配置到方法上，每次执行方法就会在缓存里做一次检查，看看是否已经用当前参数调用过这个方法了，如果调用过并且有结果在缓存里了，就不再执行实际的方法调用，而是直接返回缓存值；

这里有两点需要着重说明一下：

- 这套缓存抽象背后是通过 AOP 来实现的，所以如果执行缓存操作，那么必须访问代理后的对象（依赖注入帮我们处理好了）
- 只有那些**可幂等操作**的方法才适用于这套抽象，因为必须要保证相同的参数拥有一样的返回值。

| Spring 注解    | JSR-107 对应注解                   | 说明                                                         |
| :------------- | :--------------------------------- | :----------------------------------------------------------- |
| `@Cacheable`   | `@CacheResult`                     | 从缓存中获取对应的缓存值，没有的话就执行方法并缓存，然后返回。其中 `sync` 如果为 `true`，在调用方法时会锁住缓存，相同的参数只有一个线程会计算，其他线程等待结果 |
| `@CachePut`    | `@CachePut`                        | 直接更新缓存                                                 |
| `@CacheEvict`  | `@CacheRemove` / `@CacheRemoveAll` | 清除缓存，其中的 `allEntries` 如果设置为 `true`，则清除指定缓存 |
| `@Caching`     | 无                                 | 可以用来组合多个缓存抽象的注解，比如两个 `@CacheEvict`       |
| `@CacheConfig` | `@CacheDefaults`                   | 添加在类上，为这个类里的缓存抽象注解提供公共配置，例如统一的 `cacheNames` 和 `cacheManager` |

这些注解中有很多一样的属性（除了 `@Caching`），具体如下

- **`cacheNames`**，标识一个缓存
- **`key`**，计算缓存Key名的 SpEL 表达式
- **`keyGenerator`**，自定义的 `KeyGenerator` Bean 名称，用来生成缓存键名，与 `key` 属性互斥。
- **`cacheManager`**，缓存管理器的 Bean 名称，负责管理实际的缓存
- **`cacheResolver`**，缓存解析器的 Bean 名称，与 `cacheManager` 属性互斥
- **`condition`**，操作缓存的条件，也是用 SpEL 表达式来计算的

~~~java
@Cacheable(cacheNames="menu", condition="#name.length() < 16")
public MenuItem findByName(String name) {...}
~~~



添加依赖：

~~~xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
~~~

在配置类加上`@EnableCaching`注解即可开启使用缓存：

~~~java
@Configuration
@EnableCaching
public class Config {}
~~~

也可以在 XML 配置文件中使用 `<cache:annotation-driven/>` 标签，例如：

~~~xml
<beans xmlns="http://www.springframework.org/schema/beans"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xmlns:cache="http://www.springframework.org/schema/cache"
        xsi:schemaLocation="
        http://www.springframework.org/schema/beans
        https://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/cache
        https://www.springframework.org/schema/cache/spring-cache.xsd">

    <cache:annotation-driven/>
</beans>
~~~

使用示例：

~~~java
@Service
@CacheConfig(cacheNames = "menu")
// 类上添加的 @CacheConfig 注解配置了公共的 cacheNames
public class MenuService {
    @Autowired
    private MenuRepository menuRepository;

    @Cacheable
    public List<MenuItem> getAllMenu() {
        return menuRepository.findAll();
    }

    // 此处将方法名、name 参数与 size 参数用“-”拼接在一起作为缓存的键名。
    @Cacheable(key = "#root.methodName + '-' + #name + '-' + #size")
    public Optional<MenuItem> getByNameAndSize(String name, Size size) {
        return menuRepository.findByNameAndSize(name, size);
    }
}

~~~

预热缓存：

~~~java
@Component
@Order(1)
@Slf4j
public class MenuCacheRunner implements ApplicationRunner {
    @Autowired
    private MenuService menuService;

    @Override
    public void run(ApplicationArguments args) throws Exception {
        log.info("从数据库加载菜单列表，后续应该就在缓存里了");
        List<MenuItem> list = menuService.getAllMenu();
        log.info("共取得{}个条目。", list.size());
        menuService.getByNameAndSize("Java咖啡", Size.MEDIUM).ifPresent(m -> log.info("加载中杯Java咖啡，放入缓存，ID={}", m.getId()));
    }
}
~~~

删除缓存：

~~~java
@CacheEvict(cacheNames = "hello", key = "#id") 
public String delete(String id) {
    // 删除key为id的缓存
    return "删除成功";
}
~~~

修改缓存：

~~~java
@CachePut(cacheNames = "hello", key = "#id") 
public String update(String id) {
    return "修改后的缓存数据";
}
~~~

unless条件，condition是在调用方法之前判断条件，决定是否准备缓存。unless是在调用方法之后判断条件，决定是否不缓存。

~~~java
@Cacheable(cacheNames = "hello",unless="#result.id.contains('1')" )
// 如果SpEL条件成立，则不缓存
public User find(String id) {
    User user = new User();
    user.setId(id);
    return user;
}
~~~





 Spring 缓存抽象的默认实现为`ConcurrentHashMap`，其实 Spring 的缓存抽象能够支持多种不同的后端缓存实现，通过ChacheMananger来指定：

| 实现类                      | 底层实现            | 说明                                                      |
| :-------------------------- | :------------------ | :-------------------------------------------------------- |
| `ConcurrentMapCacheManager` | `ConcurrentHashMap` | 建议仅用于测试目的                                        |
| `NoOpCacheManager`          | 无                  | 不做任何缓存操作，可以视为关闭缓存                        |
| `CompositeCacheManager`     | 无                  | 用于组合多个不同的 `CacheManager`，会在其中遍历要找的缓存 |
| `EhCacheCacheManager`       | EhCache             | 适用于 EhCache                                            |
| `CaffeineCacheManager`      | Caffeine            | 适用于 Caffeine                                           |
| `JCacheCacheManager`        | JCache              | 适用于遵循 JSR-107 规范的缓存                             |

此外还有Redis、Hazelcast、Infinispan



SpEL基本表达式：

- 算术运算符：加（+）、减（-）、乘（*）、除（/）、求余 （%）、幂（^）、求余（MOD）和除（DIV）等算术运算符
- 关系运算符：等于（==）、不等于（!=）、大于（>）、大 于等于（>=）、小于（<）、小于等于（<=）、区间（between）运算等
- 逻辑运算符：与（and）、或（or）、非（!或NOT）
- 字符串运算符：连接（+）和截取（[ ]）
- 三目运算符
- 正则表达式匹配符matcher。例如` #{'123' matches '\\d{3}' }` 返回true。
- 变量引用符：SpEL提供了一个上下文变量的引用符“#”， 可在表达式中使用“#variableName”引用上下文变量。
- 类型访问运算符：SpEL提供了一个类型访问运算符 T(Type)。其中，“Type”表示某个Java类型，实际上对应于Java类的 java.lang.Class实例。Type必须是类的全限定名（包括包名），但是 核心包“java.lang”中的类除外。例如：\#{T(String).valueOf(1)}表示将整数1转换成 字符串。
